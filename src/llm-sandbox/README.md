# LLM Sandbox

A lightweight, portable sandbox environment for securely executing code generated by Large Language Models (LLMs).

## Overview

LLM Sandbox provides a secure execution environment for LLM-generated code using Docker containers. It isolates code execution from the host system, preventing security risks while still allowing execution of useful code.

## Features

- **Isolated Execution**: Run LLM-generated code in Docker containers
- **Multiple Container Technologies**: Support for Docker, Kubernetes, and Podman
- **Resource Limits**: Control memory, CPU usage, and execution time
- **Security**: Prevent container escape attempts, resource exhaustion, and other attacks
- **Simple API**: Easy-to-use Python API for code execution
- **Command-line Interface**: Run the sandbox from the command line

## Installation

First, activate your virtual environment:

```bash
# On Windows
venv\Scripts\activate
```

Then install the package:

```bash
# Basic installation
pip install .

# Installation with Docker support
pip install .[docker]
```

## Usage

### Basic Example

```python
from llm_sandbox import Sandbox

# Create a sandbox
sandbox = Sandbox()

# Execute code
result = sandbox.execute("""
def hello(name):
    return f"Hello, {name}!"

print(hello("world"))
""")

# Print the output
print(result.output)
```

### Configure Sandbox

```python
from llm_sandbox import Sandbox, SandboxConfig

# Configure the sandbox
config = SandboxConfig(
    memory_limit="512m",  # Limit memory usage
    cpu_limit=0.5,        # Limit CPU usage
    timeout_seconds=60,   # Set execution timeout
    network_enabled=False,  # Disable network access
    allow_file_writes=False  # Prevent file writes
)

# Create a sandbox with the configuration
sandbox = Sandbox(config)
```

### Session Management

```python
from llm_sandbox import SandboxSession

# Create a session for multiple code executions
with SandboxSession() as session:
    result1 = session.run("print('First execution')")
    result2 = session.run("print('Second execution')")
    
    print(result1.output)
    print(result2.output)
```

### Command-line Usage

```bash
# Execute a Python file
python -m llm_sandbox my_script.py

# Execute code directly
python -m llm_sandbox --code "print('Hello, world!')"

# Set execution options
python -m llm_sandbox --memory 1g --cpu 0.5 --timeout 60 my_script.py
```

## Security

LLM Sandbox implements multiple security layers:

1. **Container Isolation**: Code runs in isolated Docker containers
2. **Resource Limits**: Prevents resource exhaustion attacks
3. **Network Restrictions**: Containers have no network access by default
4. **Read-only Filesystems**: Prevents persistent file modifications
5. **Execution Timeouts**: Limits long-running processes

## Requirements

- Python 3.8+
- Docker (for Docker container support)
- Kubernetes CLI tools (for Kubernetes support)
- Podman (for Podman container support)

## License

MIT 